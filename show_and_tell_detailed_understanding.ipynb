{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from PIL import Image\n",
    "from cache import cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf.keras.models import Model  # This does not work!\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.applications import VGG16\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Directory where you want to download and save the data-set.\n",
    "# Set this before you start calling any of the functions below.\n",
    "# Use the function set_data_dir() to also update train_dir and val_dir.\n",
    "data_dir = \"data/coco/\"\n",
    "\n",
    "# Sub-directories for the training- and validation-sets.\n",
    "train_dir = \"data/coco/train2017\"\n",
    "val_dir = \"data/coco/val2017\"\n",
    "\n",
    "# Base-URL for the data-sets on the internet.\n",
    "data_url = \"http://images.cocodataset.org/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data_dir(new_data_dir):\n",
    "    \"\"\"\n",
    "    Set the base-directory for data-files and then\n",
    "    set the sub-dirs for training and validation data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure we update the global variables.\n",
    "    global data_dir, train_dir, val_dir\n",
    "\n",
    "    data_dir = new_data_dir\n",
    "    train_dir = os.path.join(new_data_dir, \"train2017\")\n",
    "    val_dir = os.path.join(new_data_dir, \"val2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_data_dir(\"/media/ruler/data_repository/Academics/data/coco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download_and_extract():\n",
    "    \"\"\"\n",
    "    Download and extract the COCO data-set if the data-files don't\n",
    "    already exist in data_dir.\n",
    "    \"\"\"\n",
    "\n",
    "    # Filenames to download from the internet.\n",
    "    filenames = [\"zips/train2017.zip\", \"zips/val2017.zip\",\n",
    "                 \"annotations/annotations_trainval2017.zip\"]\n",
    "\n",
    "    # Download these files.\n",
    "    for filename in filenames:\n",
    "        # Create the full URL for the given file.\n",
    "        url = data_url + filename\n",
    "\n",
    "        print(\"Downloading \" + url)\n",
    "\n",
    "        download.maybe_download_and_extract(url=url, download_dir=data_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
